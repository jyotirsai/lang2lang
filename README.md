# lang2lang

A language translation model built on the original Transformer network outlined in "Attention Is All You Need" by Vaswani
et. al. The encoder-decoder model architecture was reproduced from scratch in PyTorch and includes experiment tracking with MLFlow. It was trained via Google Colab on the iwslt2017 english to french dataset and can be easily reconfigured to train
on other language translation datasets.
